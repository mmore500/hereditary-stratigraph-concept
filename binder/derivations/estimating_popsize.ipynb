{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from nbmetalog import nbmetalog as nbm\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "\n",
    "sp.init_printing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylib import doubling_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbm.print_metadata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a population of $n$ individuals.\n",
    "Each individual has one gene: an unsigned integer of fixed precision (i.e., 32 bits, 64 bits, etc.).\n",
    "At outset, suppose each individual begins with gene value drawn from a uniform distribution over possible gene values.\n",
    "Then, let generations elapse with sexual recombination between individuals.\n",
    "\n",
    "If we enforce a \"gene drive\" mechanism where offspring inherit the larger of their parents' genes, the largest gene value in the population will eventually reach fixation.\n",
    "\n",
    "Introduce a random variable $\\mathbb{X}$ to represent the the magnitude of the gene value observed after fixation.\n",
    "How is $\\mathbb{X}$ distributed?\n",
    "\n",
    "If we approximate our unsigned gene as uniformly distributed between 0 and 1, it turns out to be distributed as\n",
    "\n",
    "$$\n",
    "\\mathrm{Beta}(n, 1)\n",
    "$$\n",
    "\n",
    "[(Gentle, 2008)](gentle2008computational) [via Wikipedia](https://en.wikipedia.org/wiki/Order_statistic#:~:text=Order%20statistics%20sampled%20from%20a%20uniform%20distribution%5Bedit%5D>).\n",
    "\n",
    "This probability density function of this distribution can be given as\n",
    "\n",
    "$$\n",
    "n x^{n-1}\n",
    "$$\n",
    "\n",
    "for $x$ on $[0,1]$ and 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Extend our thought experiment to $k$ independent genes, where each gene has the same fixed precision, is initialized uniformly, is inherited entirely independently from all other genes, and independently enforces the \"gene drive\" mechanism as before.\n",
    "\n",
    "Suppose we sample an individual from the population after all genes goes to fixation.\n",
    "If we observe values of $k$ fixed genes, how can we estimate the size of the population the individual was extracted from?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let us use the method of maximum likelihood estimation to determine the most likely value of $n$ given an observation of $k$ gene values after fixation.\n",
    "\n",
    "Denote the likelihood of a population size $n$ given our observations as $\\mathcal{L}(n|\\mathbb{X}_0=x_0, \\dots, \\mathbb{X}_k=x_k)$ or $\\mathcal{L}$ for short.\n",
    "Because our observations are independent, we can calculate likelihood as a product of probability densities,\n",
    "\n",
    "$\\begin{align*}\n",
    "\\mathcal{L}\n",
    "&= \\prod_{i=1}^k n x_i^{n-1}.\n",
    "\\end{align*}$\n",
    "\n",
    "Applying a logarithmic transformation for convenience,\n",
    "\n",
    "$\\begin{align*}\n",
    "\\log\\mathcal{L}\n",
    "&= \\sum_{i=1}^k \\log( n x_i^{n-1} ) \\\\\n",
    "&= (n-1) \\sum_{i=1}^k \\log( x_i ) + k \\log(n)\n",
    "\\end{align*}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To maximize $\\log\\mathcal{L}$ with respect to $n$, solve for $n$ where $\\frac{\\mathrm{d}}{\\mathrm{d}n}\\log\\mathcal{L} = 0$,\n",
    "\n",
    "$\\begin{align*}\n",
    "0\n",
    "&= \\frac{\\mathrm{d}}{\\mathrm{d}n}\\log\\mathcal{L} \\\\\n",
    "&= \\frac{\\mathrm{d}}{\\mathrm{d}n} \\Big( (n-1) \\sum_{i=1}^k \\log( x_i ) + k \\log(n) \\Big)\\\\\n",
    "&= \\sum_{i=1}^k \\log( x_i ) + k/n\\\\\n",
    "-k/n &= \\sum_{i=1}^k \\log( x_i )\\\\\n",
    "-k &= n\\sum_{i=1}^k \\log( x_i )\\\\\n",
    "n &= -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}.\n",
    "\\end{align*}$\n",
    "\n",
    "Note that $\\forall i$, $x_i \\leq 1$ so $\\log( x_i ) \\leq 0$ and $\\sum_{i=1}^k \\log( x_i ) \\leq 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To check that $n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}$ maximizes $\\log\\mathcal{L}$ rather than minimizing it, we must show that \\frac{\\mathrm{d}^2}{\\mathrm{d}n^2} < 0 at this point.\n",
    "\n",
    "$\\begin{align*}\n",
    "0 &\\stackrel{?}{>} \\frac{\\mathrm{d}^2}{\\mathrm{d}n^2} \\log\\mathcal{L}|_{n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}}\\\\\n",
    "&\\stackrel{?}{>} \\frac{\\mathrm{d}}{\\mathrm{d}n} \\sum_{i=1}^k \\log( x_i ) + k n^{-1} |_{n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}}\\\\\n",
    "&\\stackrel{?}{>} -kn^{-2} |_{n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}}\\\\\n",
    "&\\stackrel{?}{>} -k/n^{2} |_{n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}}\\\\\n",
    "&\\stackrel{?}{>} -k\\\\\n",
    "&\\stackrel{?}{<} k.\n",
    "\\end{align*}$\n",
    "\n",
    "Because $k$ is our count of 1 or more replicate observations, we have $0 \\stackrel{\\checkmark}{<} k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now have a maximum likelihood estimate $\\hat{n}_\\mathrm{mle}$ for $n$.\n",
    "\n",
    "In order to better understand our estimate, we should develop an expression for uncertainty related to the estimate.\n",
    "We can express probability that the true value of $n$ falls within a range as the fraction of total likelihood that falls within that range.\n",
    "This constitutes a Bayesian ``credible interval,'' which differs subtly from a (frequentist) confidence interval [(Porter, 1996)](porder1996interval).\n",
    "Note that this assumes a uniform prior for $n$ over $\\mathbb{R}_{\\ge 0}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To begin, calculate total likelihood $L$ by integrating over the domain of $n$.\n",
    "(For simplicity, we treat $n$ as continuous rather than discrete.)\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= \\int_{0}^{\\infty} \\mathcal{L}(n) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp(\\log\\mathcal{L}(n)) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i ) + k \\log(n)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) \\exp\\Big(k \\log(n)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) \\exp\\Big( \\log(n^k)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "Let's simplify our expression by substituting $\\sum_{i=1}^k \\log( x_i )$ as $v$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n\n",
    "\\end{align*}$\n",
    "\n",
    "and evaluate this integral with the help of computer algebra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables with assumptions for domain\n",
    "n = sp.Symbol('n', positive=True, real=True,)\n",
    "k = sp.Symbol('k', integer=True, positive=True, real=True,)\n",
    "v = sp.Symbol('v', negative=True, real=True,)\n",
    "\n",
    "likelihood = sp.exp( (n-1) * v ) * n**k\n",
    "\n",
    "# pretty print, does the expression look right?\n",
    "sp.Integral(likelihood, (n, 0, sp.oo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform integration\n",
    "likelihood_integrated_over_domain = sp.integrate(likelihood, (n, 0, sp.oo))\n",
    "likelihood_integrated_over_domain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Simplifying and substituting,\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= -\\frac{(-v)^{-k} e^{-v} \\Gamma(k+1)}{v}\\\\\n",
    "&= -\\frac{-v(-v)^{-k-1} e^{-v} \\Gamma(k+1)}{v}\\\\\n",
    "&= (-v)^{-k-1} e^{-v} \\Gamma(k+1).\n",
    "\\end{align*}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How much likelihood $L_f$ falls within a factor $f$ of our maximum likelihood estimate?\n",
    "Integrating likelihood $\\mathcal{L}$ between $\\hat{n}_\\mathrm{mle}/f$ and $f\\hat{n}_\\mathrm{mle}$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L_f\n",
    "&= \\int_{\\hat{n}_\\mathrm{mle}/f}^{f\\hat{n}_\\mathrm{mle}} \\mathcal{L}(n) \\, \\mathrm{d}n\\\\\n",
    "&= \\int_{\\frac{1}{f}\\frac{k}{-\\sum_{i=1}^k \\log( x_i )}}^{f\\frac{k}{-\\sum_{i=1}^k \\log( x_i )}} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "Once more simplifying this expression by substituting $\\sum_{i=1}^k \\log( x_i )$ as $v$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L_f\n",
    "&= \\int_{\\frac{k}{-fv}}^{\\frac{fk}{-v}} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "we will again rely on computer algebra to evaluate this integral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables with assumptions for domain\n",
    "f = sp.Symbol('f', positive=True, real=True,)\n",
    "\n",
    "credible_interval_lb = - k / (f * v)\n",
    "credible_interval_ub = - f * k / v\n",
    "\n",
    "# pretty print, does the expression look right?\n",
    "sp.Integral(\n",
    "    likelihood,\n",
    "    (n, credible_interval_lb, credible_interval_ub,),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform integration\n",
    "likelihood_integrated_over_credible_interval = sp.integrate(\n",
    "    likelihood,\n",
    "    (n, credible_interval_lb, credible_interval_ub,),\n",
    ")\n",
    "likelihood_integrated_over_credible_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify resulit\n",
    "likelihood_integrated_over_credible_interval.simplify()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can now solve for the credibilty contained within the credible interval by taking the ratio of integrated likelihoods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility = (\n",
    "    likelihood_integrated_over_credible_interval\n",
    "    / likelihood_integrated_over_domain\n",
    ")\n",
    "credibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility = credibility.simplify()\n",
    "credibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Unfortunately, there is no easy rearrangement to analytically express the number of required independent observations $k$ in terms of the required credibility and the desired creditiblity interval width factor $f$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to solve for an expression that gives f\n",
    "# which will yield 95% credibility fails\n",
    "try:\n",
    "    sp.solve(sp.Eq( credibility, 0.95 ), k)\n",
    "except NotImplementedError as e:\n",
    "    print(e)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "However, we can nonetheless efficiently compute the number of required independent observations $k$ to capture a target credibility within a particular factor of the MLE by means of exponential search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_observations_required_for_credibility(\n",
    "    target_credibility: float,\n",
    "    interval_factor: float,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Find the minimum number of observations required for a threshold amount of credibility to be contained within a factor of the MLE estimate for\n",
    "    population size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_credibility : float\n",
    "        What credibility is required for the credible interval?\n",
    "    interval_factor : float\n",
    "        What should the credible interval bounds be, as a factor of the MLE estimate?\n",
    "        For instance, 2 would indicate the credible interval should span from half of the MLE estimate to twice the MLE estimate.\n",
    "        Corresponds to $f$ in symbolic scratchwork elsewhere.\n",
    "    upper_bound : int\n",
    "        Upper bound for the binary search, inclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    assert 0.0 <= target_credibility <= 1.0\n",
    "    assert interval_factor > 1.0\n",
    "\n",
    "    predicate = lambda k_: credibility.evalf(\n",
    "        subs={\n",
    "            k : k_,\n",
    "            f : interval_factor,\n",
    "        },\n",
    "    ) >= target_credibility\n",
    "\n",
    "    return doubling_search( predicate )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How many independent observations are required to capture 95% of credibility for different credible interval sizes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_interval_factors = (\n",
    "    1.1,\n",
    "    1.5,\n",
    "    2.0,\n",
    "    3.0,\n",
    "    4.0,\n",
    "    6.0,\n",
    ")\n",
    "pd.DataFrame.from_records([\n",
    "    {\n",
    "        'Factor of MLE with 95% Credibility' : interval_factor,\n",
    "        'Num Independent Observations Required' : num_observations_required_for_credibility(0.95, interval_factor),\n",
    "    }\n",
    "for interval_factor in sampled_interval_factors])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " References\n",
    "\n",
    "[Gentle, James E. Computational statistics. Vol. 308. New York: Springer, 2009.](#gentle2008computational)\n",
    "\n",
    "[Porter, Frank. \"Interval estimation using the likelihood function.\" Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment 368.3 (1996): 793-803.](#porder1996interval)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
