{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from nbmetalog import nbmetalog as nbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "import sympy as sp\n",
    "import typing\n",
    "\n",
    "random.seed(1)\n",
    "sp.init_printing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylib import doubling_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbm.print_metadata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a population of $n$ individuals.\n",
    "Each individual has one gene: an unsigned integer of fixed precision (i.e., 32 bits, 64 bits, etc.).\n",
    "At outset, suppose each individual begins with gene value drawn from a uniform distribution over possible gene values.\n",
    "Then, let generations elapse with sexual recombination between individuals.\n",
    "\n",
    "If we enforce a \"gene drive\" mechanism where offspring inherit the larger of their parents' genes, the largest gene value in the population will eventually reach fixation.\n",
    "\n",
    "Introduce a random variable $\\mathbb{X}$ to represent the the magnitude of the gene value observed after fixation.\n",
    "How is $\\mathbb{X}$ distributed?\n",
    "\n",
    "If we approximate our unsigned gene as uniformly distributed between 0 and 1, it turns out to be distributed as\n",
    "\n",
    "$$\n",
    "\\mathrm{Beta}(n, 1)\n",
    "$$\n",
    "\n",
    "[(Gentle, 2008)](gentle2008computational) [via Wikipedia](https://en.wikipedia.org/wiki/Order_statistic#:~:text=Order%20statistics%20sampled%20from%20a%20uniform%20distribution%5Bedit%5D>).\n",
    "\n",
    "This probability density function of this distribution can be given as\n",
    "\n",
    "$$\n",
    "n x^{n-1}\n",
    "$$\n",
    "\n",
    "for $x$ on $[0,1]$ and 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deriving an Estimator for Population Size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Extend our thought experiment to $k$ independent genes, where each gene has the same fixed precision, is initialized uniformly, is inherited entirely independently from all other genes, and independently enforces the \"gene drive\" mechanism as before.\n",
    "\n",
    "Suppose we sample an individual from the population after all genes goes to fixation.\n",
    "If we observe values of $k$ fixed genes, how can we estimate the size of the population the individual was extracted from?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let us use the method of maximum likelihood estimation to determine the most likely value of $n$ given an observation of $k$ gene values after fixation.\n",
    "\n",
    "Denote the likelihood of a population size $n$ given our observations as $\\mathcal{L}(n|\\mathbb{X}_0=x_0, \\dots, \\mathbb{X}_k=x_k)$ or $\\mathcal{L}$ for short.\n",
    "Because our observations are independent, we can calculate likelihood as a product of probability densities,\n",
    "\n",
    "$\\begin{align*}\n",
    "\\mathcal{L}\n",
    "&= \\prod_{i=1}^k n x_i^{n-1}.\n",
    "\\end{align*}$\n",
    "\n",
    "Applying a logarithmic transformation for convenience,\n",
    "\n",
    "$\\begin{align*}\n",
    "\\log\\mathcal{L}\n",
    "&= \\sum_{i=1}^k \\log( n x_i^{n-1} ) \\\\\n",
    "&= (n-1) \\sum_{i=1}^k \\log( x_i ) + k \\log(n)\n",
    "\\end{align*}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To maximize $\\log\\mathcal{L}$ with respect to $n$, solve for $n$ where $\\frac{\\mathrm{d}}{\\mathrm{d}n}\\log\\mathcal{L} = 0$,\n",
    "\n",
    "$\\begin{align*}\n",
    "0\n",
    "&= \\frac{\\mathrm{d}}{\\mathrm{d}n}\\log\\mathcal{L} \\\\\n",
    "&= \\frac{\\mathrm{d}}{\\mathrm{d}n} \\Big( (n-1) \\sum_{i=1}^k \\log( x_i ) + k \\log(n) \\Big)\\\\\n",
    "&= \\sum_{i=1}^k \\log( x_i ) + k/n\\\\\n",
    "-k/n &= \\sum_{i=1}^k \\log( x_i )\\\\\n",
    "-k &= n\\sum_{i=1}^k \\log( x_i )\\\\\n",
    "n &= -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}.\n",
    "\\end{align*}$\n",
    "\n",
    "Note that $\\forall i$, $x_i \\leq 1$ so $\\log( x_i ) \\leq 0$ and $\\sum_{i=1}^k \\log( x_i ) \\leq 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To check that $n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}$ maximizes $\\log\\mathcal{L}$ rather than minimizing it, we must show that \\frac{\\mathrm{d}^2}{\\mathrm{d}n^2} < 0 at this point.\n",
    "\n",
    "$\\begin{align*}\n",
    "0 &\\stackrel{?}{>} \\frac{\\mathrm{d}^2}{\\mathrm{d}n^2} \\log\\mathcal{L}|_{n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}}\\\\\n",
    "&\\stackrel{?}{>} \\frac{\\mathrm{d}}{\\mathrm{d}n} \\sum_{i=1}^k \\log( x_i ) + k n^{-1} |_{n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}}\\\\\n",
    "&\\stackrel{?}{>} -kn^{-2} |_{n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}}\\\\\n",
    "&\\stackrel{?}{>} -k/n^{2} |_{n = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}}\\\\\n",
    "&\\stackrel{?}{>} -k\\\\\n",
    "&\\stackrel{?}{<} k.\n",
    "\\end{align*}$\n",
    "\n",
    "Because $k$ is our count of 1 or more replicate observations, we have $0 \\stackrel{\\checkmark}{<} k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deriving Credibility Intervals for Population Size Estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now have a maximum likelihood estimate $\\hat{n}_\\mathrm{mle}$ for $n$.\n",
    "\n",
    "In order to better understand our estimate, we should develop an expression for uncertainty related to the estimate.\n",
    "We can express probability that the true value of $n$ falls within a range as the fraction of total likelihood that falls within that range.\n",
    "This constitutes a Bayesian ``credible interval,'' which differs subtly from a (frequentist) confidence interval [(Porter, 1996)](porder1996interval).\n",
    "Note that this assumes a uniform prior for $n$ over $\\mathbb{R}_{\\ge 0}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To begin, calculate total likelihood $L$ by integrating over the domain of $n$.\n",
    "(For simplicity, we treat $n$ as continuous rather than discrete.)\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= \\int_{0}^{\\infty} \\mathcal{L}(n) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp(\\log\\mathcal{L}(n)) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i ) + k \\log(n)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) \\exp\\Big(k \\log(n)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) \\exp\\Big( \\log(n^k)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "Let's simplify our expression by substituting $\\sum_{i=1}^k \\log( x_i )$ as $v$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n\n",
    "\\end{align*}$\n",
    "\n",
    "and evaluate this integral with the help of computer algebra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables with assumptions for domain\n",
    "n = sp.Symbol('n', positive=True, real=True,)\n",
    "k = sp.Symbol('k', integer=True, positive=True, real=True,)\n",
    "v = sp.Symbol('v', negative=True, real=True,)\n",
    "\n",
    "likelihood = sp.exp( (n-1) * v ) * n**k\n",
    "\n",
    "# pretty print, does the expression look right?\n",
    "sp.Integral(likelihood, (n, 0, sp.oo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform integration\n",
    "likelihood_integrated_over_domain = sp.integrate(likelihood, (n, 0, sp.oo))\n",
    "likelihood_integrated_over_domain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Simplifying and substituting,\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= -\\frac{(-v)^{-k} e^{-v} \\Gamma(k+1)}{v}\\\\\n",
    "&= -\\frac{-v(-v)^{-k-1} e^{-v} \\Gamma(k+1)}{v}\\\\\n",
    "&= (-v)^{-k-1} e^{-v} \\Gamma(k+1).\n",
    "\\end{align*}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How much likelihood $L_f$ falls within a factor $f$ of our maximum likelihood estimate?\n",
    "Integrating likelihood $\\mathcal{L}$ between $\\hat{n}_\\mathrm{mle}/f$ and $f\\hat{n}_\\mathrm{mle}$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L_f\n",
    "&= \\int_{\\hat{n}_\\mathrm{mle}/f}^{f\\hat{n}_\\mathrm{mle}} \\mathcal{L}(n) \\, \\mathrm{d}n\\\\\n",
    "&= \\int_{\\frac{1}{f}\\frac{k}{-\\sum_{i=1}^k \\log( x_i )}}^{f\\frac{k}{-\\sum_{i=1}^k \\log( x_i )}} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "Once more simplifying this expression by substituting $\\sum_{i=1}^k \\log( x_i )$ as $v$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L_f\n",
    "&= \\int_{\\frac{k}{-fv}}^{\\frac{fk}{-v}} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "we will again rely on computer algebra to evaluate this integral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables with assumptions for domain\n",
    "f = sp.Symbol('f', positive=True, real=True,)\n",
    "\n",
    "credible_interval_lb = - k / (f * v)\n",
    "credible_interval_ub = - f * k / v\n",
    "\n",
    "# pretty print, does the expression look right?\n",
    "sp.Integral(\n",
    "    likelihood,\n",
    "    (n, credible_interval_lb, credible_interval_ub,),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform integration\n",
    "likelihood_integrated_over_credible_interval = sp.integrate(\n",
    "    likelihood,\n",
    "    (n, credible_interval_lb, credible_interval_ub,),\n",
    ")\n",
    "likelihood_integrated_over_credible_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify resulit\n",
    "likelihood_integrated_over_credible_interval.simplify()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can now solve for the credibilty contained within the credible interval by taking the ratio of integrated likelihoods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility = (\n",
    "    likelihood_integrated_over_credible_interval\n",
    "    / likelihood_integrated_over_domain\n",
    ")\n",
    "credibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility = credibility.simplify()\n",
    "credibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Credibility Intervals for Population Size Estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Unfortunately, there is no easy rearrangement to analytically express the number of required independent observations $k$ in terms of the required credibility and the desired creditiblity interval width factor $f$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to solve for an expression that gives f\n",
    "# which will yield 95% credibility fails\n",
    "try:\n",
    "    sp.solve(sp.Eq( credibility, 0.95 ), k)\n",
    "except NotImplementedError as e:\n",
    "    print(e)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "However, we can nonetheless efficiently compute the number of required independent observations $k$ to capture a target credibility within a particular factor of the MLE by means of exponential search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_observations_required_for_credibility(\n",
    "    target_credibility: float,\n",
    "    interval_factor: float,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Find the minimum number of observations required for a threshold amount of credibility to be contained within a factor of the MLE estimate for\n",
    "    population size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_credibility : float\n",
    "        What credibility is required for the credible interval?\n",
    "    interval_factor : float\n",
    "        What should the credible interval bounds be, as a factor of the MLE estimate?\n",
    "        For instance, 2 would indicate the credible interval should span from half of the MLE estimate to twice the MLE estimate.\n",
    "        Corresponds to $f$ in symbolic scratchwork elsewhere.\n",
    "    upper_bound : int\n",
    "        Upper bound for the binary search, inclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    assert 0.0 <= target_credibility <= 1.0\n",
    "    assert interval_factor > 1.0\n",
    "\n",
    "    predicate = lambda k_: credibility.evalf(\n",
    "        subs={\n",
    "            k : k_,\n",
    "            f : interval_factor,\n",
    "        },\n",
    "    ) >= target_credibility\n",
    "\n",
    "    return doubling_search( predicate )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How many independent observations are required to capture 95% of credibility for different credible interval sizes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_interval_factors = (\n",
    "    1.1,\n",
    "    1.5,\n",
    "    2.0,\n",
    "    3.0,\n",
    "    4.0,\n",
    "    6.0,\n",
    ")\n",
    "\n",
    "atleast95cred_intervals_df = pd.DataFrame.from_records([\n",
    "    {\n",
    "        'Factor of MLE with 95% Credibility' : interval_factor,\n",
    "        'Num Independent Observations Required' : num_observations_required_for_credibility(0.95, interval_factor),\n",
    "    }\n",
    "for interval_factor in sampled_interval_factors])\n",
    "\n",
    "atleast95cred_intervals_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Check Estimator and Credibility Intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the derived maximum likelihood estimator and credibility intervals perform on simulated experiments?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_observations(true_popsize: int, num_observations: int) -> typing.List[float]:\n",
    "    \"\"\"Simulate sampling the largest gene from within a population of `true_popsize` `num_observations` times.\"\"\"\n",
    "    return [\n",
    "        max(random.random() for __ in range(true_popsize))\n",
    "        for __ in range(num_observations)\n",
    "    ]\n",
    "\n",
    "def estimate_popsize(observations: typing.List[float]) -> float:\n",
    "    \"\"\"Use maximum likelihood estimator to estimate underlying population size given `observations`.\"\"\"\n",
    "    return -len(observations) / sum(math.log(o) for o in observations)\n",
    "\n",
    "def sample_popsize_estimate(true_popsize: int, num_observations: int) -> float:\n",
    "    \"\"\"Generate sampled largest genes from `true_popsize` population\n",
    "    and then use maximum likelihood estimator to estimate `true_popsize`.\"\"\"\n",
    "    return estimate_popsize(sample_observations(true_popsize, num_observations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate gene drive within populations and then subsequent estimates of population size from magnitude of fixed genes\n",
    "records = []\n",
    "for true_popsize in 10, 1000:\n",
    "    for __, row in atleast95cred_intervals_df.iterrows():\n",
    "        sampled_estimates = [\n",
    "            sample_popsize_estimate(\n",
    "                true_popsize,\n",
    "                int(row['Num Independent Observations Required']),\n",
    "            )\n",
    "            for __ in range(200)\n",
    "        ]\n",
    "\n",
    "        f = row['Factor of MLE with 95% Credibility']\n",
    "        num_estimates_within_credible_interval = sum(\n",
    "            true_popsize / f <= est <= true_popsize * f\n",
    "            for est in sampled_estimates\n",
    "        )\n",
    "\n",
    "        records.append({\n",
    "            **row,\n",
    "            **{\n",
    "                'True Population Size' : true_popsize,\n",
    "                'Mean Estimated Population Size' : np.mean(sampled_estimates),\n",
    "                'Median Estimated Population Size' : np.median(sampled_estimates),\n",
    "                'Normalized Mean Estimate' : np.mean(sampled_estimates) / true_popsize,\n",
    "                'Normalized Median Estimate' : np.median(sampled_estimates) / true_popsize,\n",
    "                'Factor of MLE with 95% Credibility' : f,\n",
    "                'Fraction Estimates within Credible Interval'\n",
    "                    : num_estimates_within_credible_interval / len(sampled_estimates),\n",
    "                'p As Many Estimates Outside Credible Interval'\n",
    "                    : stats.binom.cdf(num_estimates_within_credible_interval, len(sampled_estimates), 0.95),\n",
    "            },\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame.from_records(records)\n",
    "res_df.round(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum likelihood population size estimator $\\hat{n}_{\\mathrm{MLE}}$ appears to be biased towards overestimation, especially for small numbers of independent observations.\n",
    "For one independent observation, 95% credibility appears to translate to about 80% confidence.\n",
    "\n",
    "Perhaps numerical simulation paired with binomial confidence intervals could be used to produce (loose) confidence intervals for this estimation method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[Gentle, James E. Computational statistics. Vol. 308. New York: Springer, 2009.](#gentle2008computational)\n",
    "\n",
    "[Porter, Frank. \"Interval estimation using the likelihood function.\" Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment 368.3 (1996): 793-803.](#porder1996interval)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
