{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interval_search import doubling_search\n",
    "import math\n",
    "from nbmetalog import nbmetalog as nbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "import sympy\n",
    "import typing\n",
    "\n",
    "random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbm.print_metadata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "From [maximum_likelihood_estimator.ipynb](maximum_likelihood_estimator.ipynb) we have the maximum likelihood estimator for $n$ given $k$ observations of fixed gene magnitude $x_1, x_2, ... x_k$ as\n",
    "\n",
    "$\\hat{n}_\\mathrm{mle} = -\\frac{k}{\\sum_{i=1}^k \\log( x_i )}$.\n",
    "\n",
    "In order to better understand our estimate, we should develop an expression for uncertainty related to the estimate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood & Credibility\n",
    "\n",
    "We can express probability that the true value of $n$ falls within a range as the fraction of total likelihood that falls within that range.\n",
    "This constitutes a Bayesian \"credible interval,\" which differs subtly from a (frequentist) confidence interval [(Porter, 1996)](porder1996interval).\n",
    "Note that this assumes a uniform prior for $n$ over $\\mathbb{R}_{\\ge 0}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization Factor $L$\n",
    "\n",
    "To begin, calculate total likelihood $L$ by integrating over the domain of $n$.\n",
    "(For simplicity, we treat $n$ as continuous rather than discrete.)\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= \\int_{0}^{\\infty} \\mathcal{L}(n) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp(\\log\\mathcal{L}(n)) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i ) + k \\log(n)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) \\exp\\Big(k \\log(n)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) \\exp\\Big( \\log(n^k)\\Big) \\, \\mathrm{d}n \\\\\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) \\sum_{i=1}^k \\log( x_i )\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "Let's simplify our expression by substituting $\\sum_{i=1}^k \\log( x_i )$ as $v$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= \\int_{0}^{\\infty} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n\n",
    "\\end{align*}$\n",
    "\n",
    "and evaluate this integral with the help of computer algebra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables with assumptions for domain\n",
    "n = sympy.Symbol('n', positive=True, real=True,)\n",
    "k = sympy.Symbol('k', integer=True, positive=True, real=True,)\n",
    "v = sympy.Symbol('v', negative=True, real=True,)\n",
    "\n",
    "likelihood = sympy.exp( (n-1) * v ) * n**k\n",
    "\n",
    "# pretty print, does the expression look right?\n",
    "sympy.Integral(likelihood, (n, 0, sympy.oo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform integration\n",
    "likelihood_integrated_over_domain = sympy.integrate(\n",
    "    likelihood,\n",
    "    (n, 0, sympy.oo)\n",
    ")\n",
    "likelihood_integrated_over_domain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplifying and substituting,\n",
    "\n",
    "$\\begin{align*}\n",
    "L\n",
    "&= -\\frac{(-v)^{-k} e^{-v} \\Gamma(k+1)}{v}\\\\\n",
    "&= -\\frac{-v(-v)^{-k-1} e^{-v} \\Gamma(k+1)}{v}\\\\\n",
    "&= (-v)^{-k-1} e^{-v} \\Gamma(k+1).\n",
    "\\end{align*}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credibility Within Factor of MLE\n",
    "\n",
    "How much likelihood $L_f$ falls within a factor $f$ of our maximum likelihood estimate?\n",
    "Integrating likelihood $\\mathcal{L}$ between $\\hat{n}_\\mathrm{mle}/f$ and $f\\hat{n}_\\mathrm{mle}$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L_f\n",
    "&= \\int_{\\hat{n}_\\mathrm{mle}/f}^{f\\hat{n}_\\mathrm{mle}} \\mathcal{L}(n) \\, \\mathrm{d}n\\\\\n",
    "&= \\int_{\\frac{1}{f}\\frac{k}{-\\sum_{i=1}^k \\log( x_i )}}^{f\\frac{k}{-\\sum_{i=1}^k \\log( x_i )}} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "Once more simplifying this expression by substituting $\\sum_{i=1}^k \\log( x_i )$ as $v$,\n",
    "\n",
    "$\\begin{align*}\n",
    "L_f\n",
    "&= \\int_{\\frac{k}{-fv}}^{\\frac{fk}{-v}} \\exp\\Big((n-1) v\\Big) n^k \\, \\mathrm{d}n.\n",
    "\\end{align*}$\n",
    "\n",
    "we will again rely on computer algebra to evaluate this integral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables with assumptions for domain\n",
    "f = sympy.Symbol('f', positive=True, real=True,)\n",
    "\n",
    "factor_interval_lb = - k / (f * v)\n",
    "factor_interval_ub = - f * k / v\n",
    "\n",
    "# pretty print, does the expression look right?\n",
    "sympy.Integral(\n",
    "    likelihood,\n",
    "    (n, factor_interval_lb, factor_interval_ub,),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform integration\n",
    "likelihood_integrated_over_credible_interval = sympy.integrate(\n",
    "    likelihood,\n",
    "    (n, factor_interval_lb, factor_interval_ub,),\n",
    ")\n",
    "likelihood_integrated_over_credible_interval.simplify()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now solve for the credibilty contained within the credible interval by taking the ratio of integrated likelihoods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility = (\n",
    "    likelihood_integrated_over_credible_interval\n",
    "    / likelihood_integrated_over_domain\n",
    ").simplify()\n",
    "credibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Interval Factor Is Required to Capture a Target Credibility?\n",
    "\n",
    "Unfortunately, there is no easy rearrangement to analytically express the number of required independent observations $k$ in terms of the required credibility and the desired creditiblity interval width factor $f$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to solve for an expression that gives f\n",
    "# which will yield 95% credibility fails\n",
    "try:\n",
    "    sympy.solve(sympy.Eq( credibility, 0.95 ), k)\n",
    "except NotImplementedError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can nonetheless efficiently compute the number of required independent observations $k$ to capture a target credibility within a particular factor of the MLE by means of exponential search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_observations_required_for_credibility(\n",
    "    target_credibility: float,\n",
    "    interval_factor: float,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Find the minimum number of observations required for a threshold amount of credibility to be contained within a factor of the MLE estimate for\n",
    "    population size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_credibility : float\n",
    "        What credibility is required for the credible interval?\n",
    "    interval_factor : float\n",
    "        What should the credible interval bounds be, as a factor of the MLE estimate?\n",
    "        For instance, 2 would indicate the credible interval should span from half of the MLE estimate to twice the MLE estimate.\n",
    "        Corresponds to $f$ in symbolic scratchwork elsewhere.\n",
    "    upper_bound : int\n",
    "        Upper bound for the binary search, inclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    assert 0.0 <= target_credibility <= 1.0\n",
    "    assert interval_factor > 1.0\n",
    "\n",
    "    predicate = lambda k_: credibility.evalf(\n",
    "        subs={\n",
    "            k : k_,\n",
    "            f : interval_factor,\n",
    "        },\n",
    "    ) >= target_credibility\n",
    "\n",
    "    return doubling_search( predicate )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many independent observations are required to capture 95% of credibility for different credible interval size factors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_factors = (\n",
    "    1.1,\n",
    "    1.5,\n",
    "    2.0,\n",
    "    3.0,\n",
    "    4.0,\n",
    "    6.0,\n",
    ")\n",
    "\n",
    "atleast95cred_intervals_df = pd.DataFrame.from_records([\n",
    "    {\n",
    "        'Factor of MLE with 95% Credibility' : interval_factor,\n",
    "        'Num Independent Observations Required' : num_observations_required_for_credibility(0.95, interval_factor),\n",
    "    }\n",
    "for interval_factor in interval_factors])\n",
    "\n",
    "atleast95cred_intervals_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the derived maximum likelihood estimator and credibility intervals perform on simulated experiments?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_observations(true_popsize: int, num_observations: int) -> typing.List[float]:\n",
    "    \"\"\"Simulate sampling the largest gene from within a population of `true_popsize` `num_observations` times.\"\"\"\n",
    "\n",
    "    return [\n",
    "        max(random.random() for __ in range(true_popsize))\n",
    "        for __ in range(num_observations)\n",
    "    ]\n",
    "\n",
    "def estimate_popsize(observations: typing.List[float]) -> float:\n",
    "    \"\"\"Use maximum likelihood estimator to estimate underlying population size given `observations`.\"\"\"\n",
    "\n",
    "    return -len(observations) / sum(math.log(o) for o in observations)\n",
    "\n",
    "def sample_popsize_estimate(true_popsize: int, num_observations: int) -> float:\n",
    "    \"\"\"Generate sampled largest genes from `true_popsize` population\n",
    "    and then use maximum likelihood estimator to estimate `true_popsize`.\"\"\"\n",
    "\n",
    "    return estimate_popsize(sample_observations(true_popsize, num_observations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate gene drive within populations and then subsequent estimates of population size from magnitude of fixed genes\n",
    "records = []\n",
    "for true_popsize in 10, 1000:\n",
    "    for __, row in atleast95cred_intervals_df.iterrows():\n",
    "        sampled_estimates = [\n",
    "            sample_popsize_estimate(\n",
    "                true_popsize,\n",
    "                int(row['Num Independent Observations Required']),\n",
    "            )\n",
    "            for __ in range(200)\n",
    "        ]\n",
    "\n",
    "        f = row['Factor of MLE with 95% Credibility']\n",
    "        num_estimates_within_credible_interval = sum(\n",
    "            true_popsize / f <= est <= true_popsize * f\n",
    "            for est in sampled_estimates\n",
    "        )\n",
    "\n",
    "        records.append({\n",
    "            **row,\n",
    "            **{\n",
    "                'True Population Size' : true_popsize,\n",
    "                'Mean Estimated Population Size' : np.mean(sampled_estimates),\n",
    "                'Median Estimated Population Size' : np.median(sampled_estimates),\n",
    "                'Mean Normalized Error' : np.mean([abs(est - true_popsize) for est in sampled_estimates]) / true_popsize,\n",
    "                'Normalized Mean Estimate' : np.mean(sampled_estimates) / true_popsize,\n",
    "                'Normalized Median Estimate' : np.median(sampled_estimates) / true_popsize,\n",
    "                'Factor of MLE with 95% Credibility' : f,\n",
    "                'Fraction Estimates within Credible Interval'\n",
    "                    : num_estimates_within_credible_interval / len(sampled_estimates),\n",
    "                'p As Many Estimates Outside Credible Interval'\n",
    "                    : stats.binom.cdf(num_estimates_within_credible_interval, len(sampled_estimates), 0.95),\n",
    "            },\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame.from_records(records)\n",
    "res_df.round(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum likelihood population size estimator $\\hat{n}_{\\mathrm{MLE}}$ appears to be biased towards overestimation, especially for small numbers of independent observations.\n",
    "For one independent observation, 95% credibility appears to translate to about 80% confidence.\n",
    "\n",
    "Perhaps numerical simulation paired with binomial confidence intervals could be used to produce (loose) confidence intervals for this estimation method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "We derived an expression for the credibilty contained within a factor of the maximum likelihood estimate $\\hat{n}_\\mathrm{mle}$,\n",
    "\n",
    "$$\\frac{- \\gamma(k + 1, \\frac{k}{f}) + \\gamma(k + 1, f k)}{k!}.$$\n",
    "\n",
    "By its form, the credibility contained within a factor of maximum likelihood estimate $\\hat{n}_\\mathrm{mle}$ remains constant across population sizes $n$.\n",
    "Numerical simulation showed that $\\hat{n}_\\mathrm{mle}$ is biased towards overestimation, although this bias decreases with increasing independent observations $k$.\n",
    "Numerical simulation also showed a clear nonequivalence between confidence and credibility, although this dissipated with larger $k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a\n",
    "   id=\"porter1996interval\"\n",
    "   href=\"https://www.jstor.org/stable/2985006\">\n",
    "Porter, Frank. \"Interval estimation using the likelihood function.\" Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment 368.3 (1996): 793-803.\n",
    "</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
