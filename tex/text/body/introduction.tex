\section{Introduction} \label{sec:introduction}

In traditional digital evolution experiments, phylogenetic trees can be tracked perfectly as they progress \citep{bohm2017mabe,wang2018vine,lalejini2019data} rather than reconstructed afterward, as must be done in most biological studies of evolution.
Such direct phylogenetic tracking enables a dizzying suite of experimental possibilities.
In a shared-memory context, it is not difficult to maintain a complete phylogeny where offspring simply track their parent (or vice versa).
As simulations progress for longer durations, memory usage will typically grow at least linearly if population sizes are fixed, or worse if populations are growing or organisms are becoming more complex.
These problems are easily ameliorated, however, by performing garbage collection on extinct lineages and saving older history to disk \citep{bohm2017mabe,dolson2019modes}.

Phylogenetic tracking in a distributed context, where linages may traverse many machines, requires algorithmic adjustment.
However, if sufficient memory or disk space can be afforded to log all reproduction events, recording a perfect phylogeny in a distributed context is still not especially difficult.
Processes could maintain records of each reproduction event, storing the parent organism (and its associated process) with all generated offspring (and their destination processes).
As long as no data goes missing and organisms are uniquely identified globally, these ``dangling ends'' could be joined in postprocessing to weave a continuous global phylogeny.
Of course, for the huge population sizes made possible by distirbuted systems, such stitching may become a demanding task in and of itself.

However, if memory and disk space are limited, distributed phylogeny tracking becomes a more burdonsome challenge.
A naive approach might employ a server model to maintain a central store of phylogenetic data.
Processes would dispatch notifications of birth and death events to the server, which would curate (and gabage collect) phylogenetic history much the same as current serial phylogenetic tracking implementations.
However, this server model approach would present profound scalability challenges: communication and computation burden on the server process would worsen in direct proportion to processor count, and processes would frequently need to pause while waiting for confirmation that a reproduction event was successfully reported.
As organisms became more complex, large genome size could further worsen the communication burden.
A more scalable approach would record birth and death events only on the process(es) where they unfold.
However, even if it went extinct locally, any lineage that had dispatched offspring to neighboring processes could not be safely garbage collected until the extinction of that dispatched offspring's lineage could be confirmed.
So, garbage collection would require involve extinction notifications to wind back across processes each lineage had traversed.

Under a best-effort model, no system of phylogeny tracking can guarantee proper garbage collection.
For example, it would be possible for an offspring that was dispatched to a neighboring process to have failed to arrive, and both processes would need to keep going, despite the failure.
So, extinction notifications for the lineage founded by that offspring would never be dispatched --- putting in motion a memory leak of un-garbage-collectible phylogenetic history.
The situation becomes even more leaky when the possibility of extinction notifications themselves being lost.

In a distributed context --- especially, a distributed, best-effort context --- phylogenetic reconstruction (as opposed to tracking) could prove simpler and more efficient at runtime while providing sufficient power to address experimental questions of interest.
However, phylogenetic reconstruction poses its own difficulties, including
\begin{itemize}
\item accounting for heterogeneity in evolutionary rates (i.e., the rate at which mutations accumulate due to divergent mutation rates or selection pressures) between lineages \citep{lack2010identifying},
\item performing sequence alignment \citep{casci2008lining},
\item mutational saturation \citep{hagstrom2004using},
\item selecting and implementing (or using) complex and diverse algorithmic approaches \citep{kapli2020phylogenetic}, and
\item computational intensity \citep{sarkar2010hardware}.
\end{itemize}

However, the computational basis of digital artificial life experiments provides a unique opportunity: to design genome annotations that are updated with each reproduction event so as to simplify and strengthen phylogenetic reconstruction efforts.
For maximum applicability of our solution, these annotations are phenotypically neutral heritable instrumentation \citep{stanley2002evolving} and do not affect any encodings for functional genome content.

A null drift model, but this would have some of the issues above
However, the ability to set unintended inherited variance to essentially zero using computer architecture opens up other possibilities.

In this paper, we present an alternate approach that allows for explicit control over trade-offs and hard guarantees for space and time efficiency as well as (practically) hard guarantees for accuracy of phylogenetic inference.
Instead of modeling genome components undergoing neutral variation through a mutational process, we keep a record of historical checkpoints that allow comparison of two lineages to identify the range of time in which they diverged.
Careful management of these checkpoints allows for a variety of trade-off options:
\begin{itemize}
  \item linear space complexity and constant inference error,
  \item constant space complexity and linear inference error, and
  \item logarithmic space complexity and inference error as a constant proportion of time elapsed since MRCA, which we suspect will be the most broadly useful trade-off.
\end{itemize}

In Section \ref{sec:methods} we present these algorithms and then in Section \ref{sec:results} we run experiments simulating the unfolding of phylogenies observed in previous digital evolution experiments with the annotations attached and then the reconstruction of those phylogenies from extant annotations at the end of the experiment.
